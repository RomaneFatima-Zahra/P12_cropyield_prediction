{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb9aa20",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## **Imports et packages**\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57101e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from utils import save_residual_plot, save_pred_vs_true_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcf6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "INPUTS_DIR = PROJECT_ROOT / \"inputs\" / \"processed\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"model\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21c9f3",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## **Reproductibilité et chargement des données :**\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e91d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 11\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4aff0b",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## **Config**\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c49c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_path: str = \"data/clean_data.csv\"\n",
    "    target: str = \"hg/ha_yield\"\n",
    "    experiment_name: str = \"crop-yield-prediction\"\n",
    "    tracking_uri: str = \"http://127.0.0.1:5000\"   # tracking local\n",
    "    split_mode: str = \"time\"              # \"time\" ou \"random\"\n",
    "    time_split_year: int = 2010           # si split temporel: train <= 2008, test >= 2009\n",
    "    n_iter_search: int = 50              # nb essais RandomizedSearch\n",
    "    cv_folds: int = 5\n",
    "    # Variables proxi\n",
    "    COEF_IRRIGATION_HG_HA = 12000  # l'irrigation augmente le rendement de 12000 hg/ha\n",
    "    COEF_FERTILIZATION_HG_HA = 15000 # la fertilisation augmente le rendement de 15000 hg/ha\n",
    "\n",
    "\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1e4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CHARGEMENT DES DONNÉES\n",
      "✓ Dataset chargé: 28242 observations, 9 colonnes\n"
     ]
    }
   ],
   "source": [
    "# ================== 1. CHARGEMENT DES DONNÉES ==================\n",
    "print(\"\\n CHARGEMENT DES DONNÉES\")\n",
    "df = pd.read_csv(INPUTS_DIR /\"clean_data.csv\")\n",
    "print(f\"✓ Dataset chargé: {df.shape[0]} observations, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084a5f1",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## **Preprocessing**\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cebe42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>item</th>\n",
       "      <th>year</th>\n",
       "      <th>avg_rain_mm</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>area_code</th>\n",
       "      <th>hg/ha_yield</th>\n",
       "      <th>item_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albania</td>\n",
       "      <td>maize</td>\n",
       "      <td>1990</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "      <td>3</td>\n",
       "      <td>36613.00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albania</td>\n",
       "      <td>potatoes</td>\n",
       "      <td>1990</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "      <td>3</td>\n",
       "      <td>69120.22</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>rice, paddy</td>\n",
       "      <td>1990</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "      <td>3</td>\n",
       "      <td>23489.15</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albania</td>\n",
       "      <td>sorghum</td>\n",
       "      <td>1990</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "      <td>3</td>\n",
       "      <td>12383.34</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albania</td>\n",
       "      <td>soybeans</td>\n",
       "      <td>1990</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "      <td>3</td>\n",
       "      <td>7000.00</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area         item  year  avg_rain_mm  pesticides_tonnes  avg_temp  \\\n",
       "0  albania        maize  1990       1485.0              121.0     16.37   \n",
       "1  albania     potatoes  1990       1485.0              121.0     16.37   \n",
       "2  albania  rice, paddy  1990       1485.0              121.0     16.37   \n",
       "3  albania      sorghum  1990       1485.0              121.0     16.37   \n",
       "4  albania     soybeans  1990       1485.0              121.0     16.37   \n",
       "\n",
       "   area_code  hg/ha_yield  item_code  \n",
       "0          3     36613.00         56  \n",
       "1          3     69120.22        116  \n",
       "2          3     23489.15         27  \n",
       "3          3     12383.34         83  \n",
       "4          3      7000.00        236  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f3d4e",
   "metadata": {},
   "source": [
    "**Pipeline de preprocessing :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73547b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"area\", \"item\"]\n",
    "numeric = [\"year\", \"avg_rain_mm\", \"pesticides_tonnes\", \"avg_temp\"]\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), # on remplace les valeurs manquantes par most-frequent\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", cat_pipe, categorical),\n",
    "    (\"num\", num_pipe, numeric),\n",
    "    ], remainder=\"drop\" # suppression des autres colonnes.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d08d1",
   "metadata": {},
   "source": [
    "**Split temporel :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b6793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Split effectué: Train=23233, Test=5009\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"area\", \"item\", \"year\", \"avg_rain_mm\", \"pesticides_tonnes\", \"avg_temp\"] #selection des features\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[CFG.target] # target est défini dans CFG\n",
    "\n",
    "train_mask = df[\"year\"] < CFG.time_split_year\n",
    "test_mask =  df[\"year\"] >= CFG.time_split_year # ou peut également faire ~train_mask\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "print(f\"✓ Split effectué: Train={len(X_train)}, Test={len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72b593",
   "metadata": {},
   "source": [
    "feature_cols = [\"area\", \"item\", \"year\", \"avg_rain_mm\", \n",
    "                \"pesticides_tonnes\", \"avg_temp\"]\n",
    "\n",
    "Split temporel\n",
    "train_df = df[df[\"year\"] < CFG.time_split_year]\n",
    "test_df  = df[df[\"year\"] >= CFG.time_split_year]\n",
    "\n",
    "Conserver uniquement les pays présents dans les deux périodes\n",
    "common_areas = set(train_df[\"area\"]).intersection(test_df[\"area\"])\n",
    "\n",
    "train_df = train_df[train_df[\"area\"].isin(common_areas)]\n",
    "test_df  = test_df[test_df[\"area\"].isin(common_areas)]\n",
    "\n",
    "Création des jeux\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[CFG.target]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[CFG.target]\n",
    "\n",
    "print(f\"✓ Train={len(X_train)}, Test={len(X_test)}\")\n",
    "print(f\"✓ Areas communes: {len(common_areas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff810a6",
   "metadata": {},
   "source": [
    "**Définition des modèles :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d09ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DÉFINITION DES MODÈLES À COMPARER\n",
      "✓ 5 modèles configurés :\n",
      "  - Dummy\n",
      "  - Ridge\n",
      "  - RF\n",
      "  - HGB\n",
      "  - XgBoost\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDÉFINITION DES MODÈLES À COMPARER\")\n",
    "\n",
    "models = {\n",
    "    # Dummy\n",
    "    \"Dummy\": Pipeline(steps=[\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", DummyRegressor(strategy=\"mean\"))\n",
    "    ]),\n",
    "\n",
    "    # Ridge\n",
    "    \"Ridge\": Pipeline(steps=[\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", Ridge(random_state=SEED))\n",
    "    ]),\n",
    "\n",
    "    # Random Forest\n",
    "    \"RF\": Pipeline(steps=[\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(random_state=SEED, n_jobs=-1))\n",
    "    ]),\n",
    "\n",
    "    # Histogram Gradient Boosting ( plus rapide et performant )\n",
    "    \"HGB\": Pipeline(steps=[\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", HistGradientBoostingRegressor(random_state=SEED))\n",
    "    ]),\n",
    "\n",
    "    # XGBoost\n",
    "    \"XgBoost\": Pipeline(steps=[\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"model\", XGBRegressor(random_state=SEED, n_jobs=-1))\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(f\"✓ {len(models)} modèles configurés :\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5837a",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## **Entrainement des modèles**\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c64c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COMPARAISON DES MODÈLES \n",
      "\n",
      "  Analyse du modèle : Dummy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:41:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Analyse du modèle : Ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:41:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Analyse du modèle : RF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:41:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Analyse du modèle : HGB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:41:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Analyse du modèle : XgBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:41:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    }
   ],
   "source": [
    "# ==================  COMPARAISON DES MODÈLES ==================\n",
    "print(\"\\n COMPARAISON DES MODÈLES \")\n",
    "\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "    \n",
    "experiment_name = CFG.experiment_name\n",
    "# Vérifie si l'experiment existe\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "# Puis set l'experiment\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.set_tracking_uri(\"file://\" + str(Path.cwd() / \"mlruns\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "scoring = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"RMSE\": \"neg_mean_squared_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\"\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=f\"benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as parent:\n",
    "    mlflow.set_tag(\"split_mode\", CFG.split_mode)\n",
    "    mlflow.set_tag(\"seed\", SEED)\n",
    "    mlflow.log_params({\n",
    "        \"data_path\": CFG.data_path,\n",
    "        \"time_split_year\": CFG.time_split_year,\n",
    "        \"cv_folds\": CFG.cv_folds,\n",
    "        \"n_iter_search\": CFG.n_iter_search\n",
    "        })\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "         with mlflow.start_run(run_name=f\"model_{model_name}\", nested=True):\n",
    "            \n",
    "            print(f\"\\n  Analyse du modèle : {model_name}...\")\n",
    "\n",
    "            #Log des paramètres\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "            mlflow.log_param(\"random_seed\", SEED)\n",
    "            mlflow.log_param(\"train_size\", len(X_train))\n",
    "            mlflow.log_param(\"test_size\", len(X_test))\n",
    "\n",
    "\n",
    "            # Cross-validation sur le train set\n",
    "            \n",
    "            cv_results = cross_validate(\n",
    "                model, X_train, y_train,\n",
    "                cv=CFG.cv_folds, #5 folds\n",
    "                scoring=scoring,\n",
    "                return_train_score=True)\n",
    "\n",
    "            # Moyenne et écart-type des métriques CV\n",
    "            cv_r2_mean   = cv_results['test_R2'].mean()\n",
    "            cv_r2_std    = cv_results['test_R2'].std()\n",
    "            cv_rmse_mean = np.sqrt(-cv_results['test_RMSE']).mean()\n",
    "            cv_mae_mean  = -cv_results['test_MAE'].mean()\n",
    "\n",
    "            # Entraînement\n",
    "            start = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            train_time = time.time() - start\n",
    "            mlflow.log_metric(\"train_time_sec\", train_time)\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        \n",
    "            # Prédictions sur train et test\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "        \n",
    "            # Métriques train/test\n",
    "            rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "            rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "            r2_train = r2_score(y_train, y_pred_train)\n",
    "            r2_test = r2_score(y_test, y_pred_test)\n",
    "            mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "            mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "            # Calcul de l'Overfit = différence R² train/test\n",
    "            overfit = r2_train - r2_test\n",
    "\n",
    "            # Log des métriques\n",
    "            mlflow.log_metrics({\n",
    "                \"R2_Train\": r2_train,\n",
    "                \"R2_Test\": r2_test,\n",
    "                \"CV_R2_mean\": cv_r2_mean,\n",
    "                \"CV_R2_std\": cv_r2_std,\n",
    "                \"RMSE_Train\": rmse_train,\n",
    "                \"RMSE_Test\": rmse_test,\n",
    "                \"CV_RMSE_Mean\": cv_rmse_mean,\n",
    "                \"MAE_Train\": mae_train,\n",
    "                \"MAE_Test\": mae_test,\n",
    "                \"CV_MAE_Mean\": cv_mae_mean,\n",
    "                \"Overfit\": overfit\n",
    "                })\n",
    "            \n",
    "            \n",
    "            # DIAGNOSTICS VISUELS\n",
    "\n",
    "            # version précédente : \n",
    "            os.makedirs(\"artifacts\", exist_ok=True)\n",
    "            rv_path = f\"artifacts/residuals_{model_name}.png\"\n",
    "            pv_path = f\"artifacts/pred_vs_true_{model_name}.png\"\n",
    "\n",
    "            save_residual_plot(y_test.values, y_pred_test, rv_path)\n",
    "            save_pred_vs_true_plot(y_test.values, y_pred_test, pv_path)\n",
    "            mlflow.log_artifact(rv_path)\n",
    "            mlflow.log_artifact(pv_path)\n",
    "\n",
    "\n",
    "            # Sauvegarde du modèle\n",
    "            mlflow.sklearn.log_model(model, f\"model_{model_name}\")\n",
    "            \n",
    "            # Stockage des résultats\n",
    "            results.append({\n",
    "                'Model': model_name,\n",
    "                'R2_Train': r2_train,\n",
    "                'R2_Test': r2_test,\n",
    "                'CV_R2_Mean': cv_r2_mean,\n",
    "                'CV_R2_Std': cv_r2_std,\n",
    "                'RMSE_Train': rmse_train,\n",
    "                'RMSE_Test': rmse_test,\n",
    "                'CV_RMSE_Mean': cv_rmse_mean,\n",
    "                'MAE_Train': mae_train,\n",
    "                'MAE_Test': mae_test,\n",
    "                'CV_MAE_Mean': cv_mae_mean,\n",
    "                'Overfit': overfit\n",
    "                })\n",
    "            \n",
    "            # Création du tableau comparatif des modèles\n",
    "\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df = results_df.sort_values('R2_Test', ascending=False)\n",
    "            results_df.to_csv(\"artifacts/feature_importance.csv\", index=False)\n",
    "            mlflow.log_artifact(\"artifacts/feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a029bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================================================================================\n",
      "RÉSULTATS DE COMPARAISON DES MODÈLES\n",
      "======================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>CV_R2_Mean</th>\n",
       "      <th>CV_R2_Std</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>CV_RMSE_Mean</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>CV_MAE_Mean</th>\n",
       "      <th>Overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>0.950765</td>\n",
       "      <td>0.667423</td>\n",
       "      <td>0.140116</td>\n",
       "      <td>2935.423338</td>\n",
       "      <td>21182.480086</td>\n",
       "      <td>45220.408438</td>\n",
       "      <td>915.933461</td>\n",
       "      <td>10651.843921</td>\n",
       "      <td>25235.458844</td>\n",
       "      <td>0.047962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.985921</td>\n",
       "      <td>0.950386</td>\n",
       "      <td>0.727602</td>\n",
       "      <td>0.113506</td>\n",
       "      <td>9762.469030</td>\n",
       "      <td>21263.809769</td>\n",
       "      <td>41199.634821</td>\n",
       "      <td>6102.463806</td>\n",
       "      <td>12319.883681</td>\n",
       "      <td>24068.981217</td>\n",
       "      <td>0.035535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.967718</td>\n",
       "      <td>0.933805</td>\n",
       "      <td>0.718503</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>14782.714802</td>\n",
       "      <td>24561.294961</td>\n",
       "      <td>41729.613384</td>\n",
       "      <td>9042.238248</td>\n",
       "      <td>14593.325171</td>\n",
       "      <td>23963.437958</td>\n",
       "      <td>0.033913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.762880</td>\n",
       "      <td>0.725296</td>\n",
       "      <td>0.602139</td>\n",
       "      <td>0.092263</td>\n",
       "      <td>40064.410430</td>\n",
       "      <td>50034.824976</td>\n",
       "      <td>51022.189594</td>\n",
       "      <td>27892.401399</td>\n",
       "      <td>33355.235455</td>\n",
       "      <td>32793.653103</td>\n",
       "      <td>0.037584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021410</td>\n",
       "      <td>-0.007882</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>82276.215796</td>\n",
       "      <td>96480.528976</td>\n",
       "      <td>82143.083776</td>\n",
       "      <td>62234.701261</td>\n",
       "      <td>69103.071837</td>\n",
       "      <td>62328.887754</td>\n",
       "      <td>0.021410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  R2_Train   R2_Test  CV_R2_Mean  CV_R2_Std    RMSE_Train  \\\n",
       "2       RF  0.998727  0.950765    0.667423   0.140116   2935.423338   \n",
       "4  XgBoost  0.985921  0.950386    0.727602   0.113506   9762.469030   \n",
       "3      HGB  0.967718  0.933805    0.718503   0.126740  14782.714802   \n",
       "1    Ridge  0.762880  0.725296    0.602139   0.092263  40064.410430   \n",
       "0    Dummy  0.000000 -0.021410   -0.007882   0.010104  82276.215796   \n",
       "\n",
       "      RMSE_Test  CV_RMSE_Mean     MAE_Train      MAE_Test   CV_MAE_Mean  \\\n",
       "2  21182.480086  45220.408438    915.933461  10651.843921  25235.458844   \n",
       "4  21263.809769  41199.634821   6102.463806  12319.883681  24068.981217   \n",
       "3  24561.294961  41729.613384   9042.238248  14593.325171  23963.437958   \n",
       "1  50034.824976  51022.189594  27892.401399  33355.235455  32793.653103   \n",
       "0  96480.528976  82143.083776  62234.701261  69103.071837  62328.887754   \n",
       "\n",
       "    Overfit  \n",
       "2  0.047962  \n",
       "4  0.035535  \n",
       "3  0.033913  \n",
       "1  0.037584  \n",
       "0  0.021410  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Création du tableau comparatif des modèles\n",
    "print(\"\\n\" + \"=\"*150)\n",
    "print(\"RÉSULTATS DE COMPARAISON DES MODÈLES\")\n",
    "print(\"=\"*150)\n",
    "display(results_df)\n",
    "print(\"=\"*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf78f80",
   "metadata": {},
   "source": [
    "En comparant les 5 modèles nous constatons que Random Forest, Xgboost et Hist Gradient Boost se distinguent par leur performances.\n",
    "\n",
    "- RF  :\n",
    "    - RF affiche un R2 de 0,66 en cross-validation, puis 0.99 en phase de train et 0.95 en phase de test. Le modèle explique 95.08% de la variance du rendement.\n",
    "\n",
    "    - Cela voudrait dire que pendant la validation croisée la performance du modèle est moyenne, puis la qualité s'améliore fortement pendant l'entrainement pour approcher la perfection (presque 1), et baisse ensuite à 0,95 en phase de test.\n",
    "\n",
    "    - Le modèle apprend exceptionnellement bien pendant l'entrainement mais ne généralise pas de la même manière. Ceci indique que le modèle est en surapprentissage. La mesure des erreurs est plus faible en Train que en Test.\n",
    "\n",
    "    - L'erreur moyenne des prédictions est de ~21,000 hg/ha. Si le rendement réel d'un agriculteur pour une culture est de 40,000 hg/ha, la prédiction sera entre 21,000 et 61,000 hg/ha.\n",
    "    \n",
    "    - En moyenne, la prédiction s'écarte de ~10,652 hg/ha de la réalité. Ce qui acceptable.\n",
    "\n",
    "    - Globalment, la performance de ce modèle reste très bonne malgé le léger sur-aprentissage.\n",
    " \n",
    " \n",
    "- XGBoost :\n",
    "    - Le modèle affiche un R2 de 0,73 en CV, puis 0,98 en train et 0,95 en Test. Le modèle explique 95 % de la variance du rendement, ce qui atteste de sa bonne capacité de généralisation. La performance du modèle est très bonne pendant la validation croisée, et également en Train et Test, avec moins d'overfitting comparé au modèle RF.\n",
    "\n",
    "    - L'erreur moyenne de prédiction est presque similaire à celle du RF soit environ 21,000 hg/ha, et la prédiction s'écarte en moyenne de 12319 hg/ha de la réalité. Les erreurs du modèles sont acceptables, ainsi que l'overfitting qui est moins élevé que pour RF.\n",
    "\n",
    "    - XGBoost a des performance presque similaires à celle du RF, avec un overfitting plus léger, mais une moyenne d'erreur de prédiction de rendement plus élevée.\n",
    "\n",
    "- Hist Gradient Boost : \n",
    "    - Le modèle affiche un R2 de 0,72 en CV, 0,97 en train et 0,93 en test. Le modèle explique 93% de la variance des rendements.\n",
    "    La performance de ce modèle est également très bonne, mais celle du XGBoost et RF restent meilleures.\n",
    "\n",
    "    - Les erreurs du modèle sont acceptables mais plus élevées que celle du RF et Xgboost, avec un overfitting plus bas que pour RF.\n",
    "\n",
    " -  Nous retenons que Random Forest et XGBoost sont les deux modèles qui se distinguent par leurs bonnes performances. Nous allons maintenant procéder à une optimisation des hyperparamètres pour améliorer encore plus leur performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec02f2",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## **Optimisation**\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa82ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grille d'hyperparamètres selon le modèle\n",
    "\n",
    "def get_param_grid(model_name: str) -> dict:\n",
    "    if model_name == \"RF\":\n",
    "        return {\n",
    "            \"model__n_estimators\": [300, 600, 1000],\n",
    "            \"model__max_depth\": [10, 20, 30, None],\n",
    "            \"model__min_samples_leaf\": [1, 3, 5, 10, 20],\n",
    "            \"model__min_samples_split\": [2, 5, 10, 20],\n",
    "            \"model__max_features\": [\"sqrt\", \"log2\", 0.5, 0.8],\n",
    "            \"model__bootstrap\": [True, False],\n",
    "        }\n",
    "\n",
    "    elif model_name == \"XgBoost\":\n",
    "        return {\n",
    "            \"model__n_estimators\": [500, 1000, 2000],\n",
    "            \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"model__max_depth\": [3, 4, 6, 8],\n",
    "            \"model__min_child_weight\": [1, 3, 5, 10],\n",
    "            \"model__subsample\": [0.6, 0.8, 1.0],\n",
    "            \"model__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"model__gamma\": [0, 0.1, 0.5, 1.0],\n",
    "            \"model__reg_alpha\": [0, 0.1, 1.0],\n",
    "            \"model__reg_lambda\": [1.0, 5.0, 10.0],\n",
    "        }\n",
    "\n",
    "    elif model_name == \"HGB\":\n",
    "        return {\n",
    "            \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"model__max_iter\": [300, 600, 1200],\n",
    "            \"model__max_depth\": [3, 5, 8, None],\n",
    "            \"model__min_samples_leaf\": [5, 10, 20, 50],\n",
    "            \"model__l2_regularization\": [0, 0.1, 1.0, 5.0, 10.0],\n",
    "            \"model__max_bins\": [128, 255],\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Modèle non supporté : {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9555fdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OPTIMISATION DES MEILLEURS MODÈLES\n",
      "✓ Modèles à optimiser : ['RF', 'XgBoost', 'HGB']\n",
      "\n",
      "========== OPTIMISATION : RF ==========\n",
      "✓ Lancement de RandomizedSearchCV...\n",
      "  Nombre d'itérations: 50\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "✓ Meilleurs hyperparamètres trouvés:\n",
      "  model__n_estimators: 1000\n",
      "  model__min_samples_split: 20\n",
      "  model__min_samples_leaf: 1\n",
      "  model__max_features: sqrt\n",
      "  model__max_depth: None\n",
      "  model__bootstrap: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:46:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ RÉSULTATS DU MODÈLE OPTIMISÉ:\n",
      "R² Train   : 0.9833\n",
      "R² Test    : 0.9337\n",
      "RMSE Train : 10639.1255\n",
      "RMSE Test  : 24577.8615\n",
      "MAE Train   : 4999.4925\n",
      "MAE Test   : 13586.3844\n",
      "\n",
      "========== OPTIMISATION : XgBoost ==========\n",
      "✓ Lancement de RandomizedSearchCV...\n",
      "  Nombre d'itérations: 50\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "✓ Meilleurs hyperparamètres trouvés:\n",
      "  model__subsample: 0.6\n",
      "  model__reg_lambda: 10.0\n",
      "  model__reg_alpha: 0.1\n",
      "  model__n_estimators: 2000\n",
      "  model__min_child_weight: 1\n",
      "  model__max_depth: 4\n",
      "  model__learning_rate: 0.05\n",
      "  model__gamma: 0.5\n",
      "  model__colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:47:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ RÉSULTATS DU MODÈLE OPTIMISÉ:\n",
      "R² Train   : 0.9822\n",
      "R² Test    : 0.9463\n",
      "RMSE Train : 10963.7393\n",
      "RMSE Test  : 22113.0633\n",
      "MAE Train   : 7033.9058\n",
      "MAE Test   : 13215.1716\n",
      "\n",
      "========== OPTIMISATION : HGB ==========\n",
      "✓ Lancement de RandomizedSearchCV...\n",
      "  Nombre d'itérations: 50\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "✓ Meilleurs hyperparamètres trouvés:\n",
      "  model__min_samples_leaf: 5\n",
      "  model__max_iter: 600\n",
      "  model__max_depth: None\n",
      "  model__max_bins: 255\n",
      "  model__learning_rate: 0.1\n",
      "  model__l2_regularization: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 20:49:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ RÉSULTATS DU MODÈLE OPTIMISÉ:\n",
      "R² Train   : 0.9943\n",
      "R² Test    : 0.9576\n",
      "RMSE Train : 6211.9696\n",
      "RMSE Test  : 19665.0725\n",
      "MAE Train   : 3661.8908\n",
      "MAE Test   : 10714.7354\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as parent_opt:\n",
    "\n",
    "    print(\"\\n OPTIMISATION DES MEILLEURS MODÈLES\")\n",
    "    top_models = results_df.head(3)[\"Model\"].tolist()\n",
    "    print(\"✓ Modèles à optimiser :\", top_models)\n",
    "\n",
    "    optimized_results = []\n",
    "    optimized_models = {}\n",
    "\n",
    "    for model_name in top_models:\n",
    "        \n",
    "        print(f\"\\n========== OPTIMISATION : {model_name} ==========\")\n",
    "\n",
    "        base_pipeline = models[model_name]  \n",
    "\n",
    "        # Grille d’hyperparamètres selon le modèle\n",
    "        param_grid = get_param_grid(model_name)\n",
    "\n",
    "        print(f\"✓ Lancement de RandomizedSearchCV...\")\n",
    "        print(f\"  Nombre d'itérations:\", CFG.n_iter_search)\n",
    "\n",
    "        # RandomizedSearchCV\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=base_pipeline, \n",
    "            param_distributions=param_grid,\n",
    "            n_iter=CFG.n_iter_search, #  nombre d’essais (clé du gain de temps)\n",
    "            cv=CFG.cv_folds, # 5 folds\n",
    "            scoring='r2', n_jobs=-1, verbose=1, random_state=SEED\n",
    "            )\n",
    "        \n",
    "        # Entrainement\n",
    "        random_search.fit(X_train, y_train)\n",
    "    \n",
    "        # Meilleurs paramètres\n",
    "        best_params = random_search.best_params_\n",
    "        print(f\"\\n✓ Meilleurs hyperparamètres trouvés:\")\n",
    "\n",
    "        optimized_model = random_search.best_estimator_\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"Optimized_{model_name}\", nested=True):\n",
    "            \n",
    "            # Log des paramètres optimisés\n",
    "            for param, value in random_search.best_params_.items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "                mlflow.log_param(f\"best_{param}\", value)\n",
    "    \n",
    "            #Modèle optimisé\n",
    "            optimized_model = random_search.best_estimator_\n",
    "    \n",
    "            # Prédictions\n",
    "            y_pred_train_opt = optimized_model.predict(X_train)\n",
    "            y_pred_test_opt = optimized_model.predict(X_test)\n",
    "    \n",
    "            # Métriques finales\n",
    "            \n",
    "            r2_train_opt = r2_score(y_train, y_pred_train_opt)\n",
    "            r2_test_opt = r2_score(y_test, y_pred_test_opt)\n",
    "\n",
    "            rmse_train_opt = np.sqrt(mean_squared_error(y_train, y_pred_train_opt))\n",
    "            rmse_test_opt = np.sqrt(mean_squared_error(y_test, y_pred_test_opt))\n",
    "\n",
    "            mae_train_opt = mean_absolute_error(y_train, y_pred_train_opt)\n",
    "            mae_test_opt = mean_absolute_error(y_test, y_pred_test_opt)\n",
    "\n",
    "            # Calcul de l'Overfit = différence R² train/test\n",
    "            overfit_opt = r2_train_opt - r2_test_opt\n",
    "\n",
    "            # Log des métriques\n",
    "            mlflow.log_metrics({\n",
    "                \"R2_train\": r2_train_opt,\n",
    "                \"R2_test\": r2_test_opt,\n",
    "                \"RMSE_train\": rmse_train_opt,\n",
    "                \"RMSE_test\": rmse_test_opt,\n",
    "                \"MAE_train\": mae_train_opt,\n",
    "                \"MAE_test\": mae_test_opt,\n",
    "                \"Overfit\": overfit_opt\n",
    "                })\n",
    "\n",
    "            # Log CV results\n",
    "            cv_df = pd.DataFrame(random_search.cv_results_)\n",
    "            cv_path = f\"artifacts/cv_results_{model_name}.csv\"\n",
    "            cv_df.to_csv(cv_path, index=False)\n",
    "            mlflow.log_artifact(cv_path)\n",
    "            mlflow.log_metric(\"CV_best_score\", random_search.best_score_)\n",
    "\n",
    "            # diagnostics visuels - Artefacts\n",
    "            os.makedirs(\"artifacts\", exist_ok=True)\n",
    "            rv_path = f\"artifacts/residuals_opt_{model_name}.png\"\n",
    "            pv_path = f\"artifacts/pred_vs_true_opt_{model_name}.png\"\n",
    "            save_residual_plot(y_test.values, y_pred_test_opt, rv_path)\n",
    "            save_pred_vs_true_plot(y_test.values, y_pred_test_opt, pv_path)\n",
    "            mlflow.log_artifact(rv_path)\n",
    "            mlflow.log_artifact(pv_path)\n",
    "\n",
    "            # Affichage des métriques : \n",
    "            print(f\"\\n✓ RÉSULTATS DU MODÈLE OPTIMISÉ:\")\n",
    "            print(f\"R² Train   : {r2_train_opt:.4f}\")\n",
    "            print(f\"R² Test    : {r2_test_opt:.4f}\")\n",
    "            print(f\"RMSE Train : {rmse_train_opt:.4f}\")\n",
    "            print(f\"RMSE Test  : {rmse_test_opt:.4f}\")\n",
    "            print(f\"MAE Train   : {mae_train_opt:.4f}\")\n",
    "            print(f\"MAE Test   : {mae_test_opt:.4f}\")\n",
    "\n",
    "            optimized_results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"R2_train_opt\" : r2_train_opt,\n",
    "                \"R2_test_opt\": r2_test_opt,\n",
    "                \"RMSE_train_opt\" : rmse_train_opt,\n",
    "                \"RMSE_test_opt\": rmse_test_opt,\n",
    "                \"MAE_train_opt\": mae_train_opt,\n",
    "                \"MAE_test_opt\": mae_test_opt,\n",
    "                'Overfit': overfit_opt,\n",
    "                \"Best_Params\": best_params\n",
    "                })\n",
    "\n",
    "            optimized_models[model_name] = optimized_model\n",
    "            # Log du modèle optimisé\n",
    "            mlflow.sklearn.log_model(optimized_model, \"optimized_model\")\n",
    "\n",
    "              # Tags métier\n",
    "            mlflow.set_tag(\"business_goal\", \"maximize_yield_and_economic_return\")\n",
    "            mlflow.set_tag(\"target\", CFG.target)\n",
    "\n",
    "            optimized_results_df = pd.DataFrame(optimized_results)\n",
    "            optimized_results_df = optimized_results_df.sort_values(\"R2_test_opt\", ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0599e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2_train_opt</th>\n",
       "      <th>R2_test_opt</th>\n",
       "      <th>RMSE_train_opt</th>\n",
       "      <th>RMSE_test_opt</th>\n",
       "      <th>MAE_train_opt</th>\n",
       "      <th>MAE_test_opt</th>\n",
       "      <th>Overfit</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.994300</td>\n",
       "      <td>0.957566</td>\n",
       "      <td>6211.969607</td>\n",
       "      <td>19665.072457</td>\n",
       "      <td>3661.890820</td>\n",
       "      <td>10714.735401</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>{'model__min_samples_leaf': 5, 'model__max_ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.982243</td>\n",
       "      <td>0.946344</td>\n",
       "      <td>10963.739315</td>\n",
       "      <td>22113.063284</td>\n",
       "      <td>7033.905814</td>\n",
       "      <td>13215.171607</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>{'model__subsample': 0.6, 'model__reg_lambda':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.983279</td>\n",
       "      <td>0.933716</td>\n",
       "      <td>10639.125466</td>\n",
       "      <td>24577.861537</td>\n",
       "      <td>4999.492478</td>\n",
       "      <td>13586.384354</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>{'model__n_estimators': 1000, 'model__min_samp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  R2_train_opt  R2_test_opt  RMSE_train_opt  RMSE_test_opt  \\\n",
       "2      HGB      0.994300     0.957566     6211.969607   19665.072457   \n",
       "1  XgBoost      0.982243     0.946344    10963.739315   22113.063284   \n",
       "0       RF      0.983279     0.933716    10639.125466   24577.861537   \n",
       "\n",
       "   MAE_train_opt  MAE_test_opt   Overfit  \\\n",
       "2    3661.890820  10714.735401  0.036733   \n",
       "1    7033.905814  13215.171607  0.035899   \n",
       "0    4999.492478  13586.384354  0.049563   \n",
       "\n",
       "                                         Best_Params  \n",
       "2  {'model__min_samples_leaf': 5, 'model__max_ite...  \n",
       "1  {'model__subsample': 0.6, 'model__reg_lambda':...  \n",
       "0  {'model__n_estimators': 1000, 'model__min_samp...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9976f94",
   "metadata": {},
   "source": [
    "En comparant les 3 meilleurs modèles optimisés nous retenons les constats suivants :\n",
    "\n",
    "- Pour Random Forest : \n",
    "    -  Légère baisse de l'overfiting ( on passe de 0.047 à 0.036 )\n",
    "    -  Légère baisse du R2 ( train = 0.983 vs 0.998 et test = 0.933 vs 0.950  )\n",
    "    - RMSE et MAE plus élevées pour le RF optimisé.\n",
    "\n",
    "\n",
    "- Pour XGBoost : \n",
    "    - Overfitting identique (0.035)\n",
    "    - R2 subtilement moins élevé (0.946 vs 0.950 en test)\n",
    "    - RMSE et MAE plus élevées.\n",
    "\n",
    "\n",
    "- Pour HGB : \n",
    "    - Overfitting légèrement plus bas ( 0.036 vs 0.033 )\n",
    "    - R2 amélioré en train et en test ( on passe d'un R2 de 0.950 avant optimisation à 0.957 en test )\n",
    "    - RMSE et MAE moins élevées. ( RMSE = 19665, et MAE= 10714 )\n",
    "    \n",
    "\n",
    "**Les 3 modèles ont des performances légèrement différentes, mais HGB se distingue, avec moins de sur-aprentissage, et des erreurs moins élévées. Dans un contexte métier de prédiction de rendement en agriculture, nous avons besoin de minimiser les erreurs moyennes des prédictions fournies au agriculteur. Nous allons donc retenir comme model le HIST GRADIENT BOOST optimisé, dont les valeurs prédites ne s'écarte en moyenne que de 10714 hg/ha.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375dd945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ANALYSE DE L'IMPORTANCE DES VARIABLES\n",
      "\n",
      "============================================================\n",
      "IMPORTANCE DES VARIABLES\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item</td>\n",
       "      <td>71188.856808</td>\n",
       "      <td>821.364324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area</td>\n",
       "      <td>15450.016641</td>\n",
       "      <td>327.273959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>avg_temp</td>\n",
       "      <td>13184.805172</td>\n",
       "      <td>195.977642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pesticides_tonnes</td>\n",
       "      <td>8319.583735</td>\n",
       "      <td>259.738316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_rain_mm</td>\n",
       "      <td>6305.237289</td>\n",
       "      <td>125.287516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance_mean  importance_std\n",
       "1               item     71188.856808      821.364324\n",
       "0               area     15450.016641      327.273959\n",
       "5           avg_temp     13184.805172      195.977642\n",
       "4  pesticides_tonnes      8319.583735      259.738316\n",
       "3        avg_rain_mm      6305.237289      125.287516\n",
       "2               year         0.000000        0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================== IMPORTANCE DES VARIABLES ==================\n",
    "print(\"\\n ANALYSE DE L'IMPORTANCE DES VARIABLES\")\n",
    "\n",
    "best_hgb = optimized_models[\"HGB\"]\n",
    "\n",
    "perm = permutation_importance(\n",
    "    estimator=best_hgb,          # pipeline complet\n",
    "    X=X_test,                    # X brut avant preprocessing\n",
    "    y=y_test,                    # y brut\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_repeats=10,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\": X_test.columns,   # les colonnes brutes avant preprocessing\n",
    "    \"importance_mean\": perm.importances_mean,\n",
    "    \"importance_std\": perm.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    " \n",
    "# Log de l'importance dans MLflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"feature_importance_HGB\", nested=True):\n",
    "\n",
    "    # Tags\n",
    "    mlflow.set_tag(\"model_name\", \"HGB\")\n",
    "    mlflow.set_tag(\"interpretability_method\", \"permutation_importance\")\n",
    "    mlflow.set_tag(\"scoring\", \"neg_mean_absolute_error\")\n",
    "\n",
    "    # Sauvegarde CSV\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "    perm_imp_path = \"artifacts/permutation_importance_HGB.csv\"\n",
    "    perm_df.to_csv(perm_imp_path, index=False)\n",
    "    mlflow.log_artifact(perm_imp_path)\n",
    "\n",
    "    # Log top-k importances comme métriques (optionnel mais excellent)\n",
    "    for i, row in perm_df.head(10).iterrows():\n",
    "        mlflow.log_metric(f\"FI_{row['feature']}\", row[\"importance_mean\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPORTANCE DES VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "display(perm_df)\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df929e",
   "metadata": {},
   "source": [
    "En Analysant la Permutation Feature importance nous constatons que le premier facteur impactant le rendement c'est le type de culture, puis le pays de culture, et ensuite des températures dans le pays de culture, l'usage de pesticide et la pluie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a48c5",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## **Sauvegarde du Modèle**\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe41b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèle sauvegardé ici : /Users/fatiza/Documents/DATA SCIENTIST/Projet12/OC/p12/model/hgb_optimized.joblib\n"
     ]
    }
   ],
   "source": [
    "# chemin du modèle\n",
    "model_path = MODEL_DIR / \"hgb_optimized.joblib\"\n",
    "\n",
    "# sauvegarde\n",
    "joblib.dump(best_hgb, model_path)\n",
    "\n",
    "print(f\"✅ Modèle sauvegardé ici : {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898050cf",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## **Test du moteur de prediction**\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d30e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# Fonction pour ajouter l'effet de l'irrigation et fertilization sur le rendement \n",
    "#================================================================================\n",
    "\n",
    "def apply_optional_scenarios(yield_hg_ha: float, irrigation: bool = False, fertilizer: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Post-ajustement additif (what-if) pour irrigation/fertilisation.\n",
    "    Hypothèse: effet moyen constant, additif.\n",
    "    \"\"\"\n",
    "    adj = 0.0\n",
    "    if irrigation:\n",
    "        adj += 12000\n",
    "    if fertilizer:\n",
    "        adj += 15000\n",
    "    return yield_hg_ha + adj\n",
    "\n",
    "#================================================================================\n",
    "# Fonction pour ajuster le prix vs unité de rendement\n",
    "#================================================================================\n",
    "\n",
    "def compute_revenue_per_ha(yield_hg_ha: float, price_value: float, price_unit: str = \"eur_per_t\") -> float:\n",
    "    \"\"\"\n",
    "    Convertit un rendement (hg/ha) en revenu/ha selon une unité de prix.\n",
    "    - eur_per_t : €/tonne  -> revenue = yield_hg_ha * price/10_000\n",
    "    - eur_per_kg: €/kg     -> revenue = yield_hg_ha * price/10\n",
    "    - eur_per_hg: €/hg     -> revenue = yield_hg_ha * price\n",
    "    \"\"\"\n",
    "    u = price_unit.lower().strip()\n",
    "    if u in [\"eur_per_t\", \"€/t\", \"euro_per_tonne\"]:\n",
    "        return yield_hg_ha * (price_value / 10_000)\n",
    "    if u in [\"eur_per_kg\", \"€/kg\", \"euro_per_kg\"]:\n",
    "        return yield_hg_ha * (price_value / 10)\n",
    "    if u in [\"eur_per_hg\", \"€/hg\", \"euro_per_hg\"]:\n",
    "        return yield_hg_ha * price_value\n",
    "    raise ValueError(f\"Unsupported price_unit: {price_unit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20c29b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_hgb\n",
    "\n",
    "# ========================================================\n",
    "# Moteur de Prediction + 2 recommenders (yield vs revenue)\n",
    "# ========================================================\n",
    "def predict_yield_hg_ha(\n",
    "    model, *,\n",
    "    area: str, item: str, year: int,\n",
    "    avg_rain_mm: float, pesticides_tonnes: float, avg_temp: float,\n",
    "    irrigation: bool = False, fertilizer: bool = False ) -> float:\n",
    "    X_in = pd.DataFrame([{\n",
    "        \"area\": area,\n",
    "        \"item\": item,\n",
    "        \"year\": year,\n",
    "        \"avg_rain_mm\": avg_rain_mm,\n",
    "        \"pesticides_tonnes\": pesticides_tonnes,\n",
    "        \"avg_temp\": avg_temp\n",
    "        }])\n",
    "    base_pred = float(model.predict(X_in)[0])\n",
    "    return apply_optional_scenarios(base_pred, irrigation=irrigation, fertilizer=fertilizer)\n",
    "\n",
    "# ========================================================\n",
    "# Moteur de Recommendation ( Hg/ha yield & rentabilité)\n",
    "# ========================================================\n",
    "def recommend_by_yield(\n",
    "    model, *,\n",
    "    area: str, year: int,\n",
    "    avg_rain_mm: float, pesticides_tonnes: float, avg_temp: float,\n",
    "    candidate_items: list[str],\n",
    "    irrigation: bool = False, fertilizer: bool = False,\n",
    "    top_k: int = 5) -> pd.DataFrame:\n",
    "    X_in = pd.DataFrame([{\n",
    "        \"area\": area,\n",
    "        \"item\": it,\n",
    "        \"year\": year,\n",
    "        \"avg_rain_mm\": avg_rain_mm,\n",
    "        \"pesticides_tonnes\": pesticides_tonnes,\n",
    "        \"avg_temp\": avg_temp\n",
    "    } for it in candidate_items])\n",
    "\n",
    "    base_preds = model.predict(X_in).astype(float)\n",
    "    adj = (CFG.COEF_IRRIGATION_HG_HA if irrigation else 0.0) + (CFG.COEF_FERTILIZATION_HG_HA if fertilizer else 0.0)\n",
    "    preds = base_preds + adj\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"item\": candidate_items,\n",
    "        \"pred_yield_hg_ha\": preds,\n",
    "        \"pred_yield_t_ha\": preds / 10000,\n",
    "        \"irrigation\": irrigation,\n",
    "        \"fertilizer\": fertilizer\n",
    "    }).sort_values(\"pred_yield_hg_ha\", ascending=False)\n",
    "\n",
    "    return out.head(top_k).reset_index(drop=True)\n",
    "\n",
    "def recommend_by_revenue(\n",
    "    model, *,\n",
    "    area: str, year: int,\n",
    "    avg_rain_mm: float, pesticides_tonnes: float, avg_temp: float,\n",
    "    candidate_items: list[str],\n",
    "    prices: dict[str, float],\n",
    "    price_unit: str = \"eur_per_t\",\n",
    "    irrigation: bool = False, fertilizer: bool = False,\n",
    "    top_k: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    # garder uniquement les items dont l'agriculteur a fourni le prix\n",
    "    items = [it for it in candidate_items if it in prices]\n",
    "    if len(items) == 0:\n",
    "        raise ValueError(\"No candidate items have a provided price. Provide prices like {'maize': 180, ...}.\")\n",
    "\n",
    "    X_in = pd.DataFrame([{\n",
    "        \"area\": area,\n",
    "        \"item\": it,\n",
    "        \"year\": year,\n",
    "        \"avg_rain_mm\": avg_rain_mm,\n",
    "        \"pesticides_tonnes\": pesticides_tonnes,\n",
    "        \"avg_temp\": avg_temp\n",
    "    } for it in items])\n",
    "\n",
    "    base_preds = model.predict(X_in).astype(float)\n",
    "    adj = (CFG.COEF_IRRIGATION_HG_HA if irrigation else 0.0) + (CFG.COEF_FERTILIZATION_HG_HA if fertilizer else 0.0)\n",
    "    preds = base_preds + adj\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"item\": items,\n",
    "        \"pred_yield_hg_ha\": preds,\n",
    "        \"pred_yield_t_ha\": preds / 10_000,\n",
    "        \"price_value\": [prices[it] for it in items],\n",
    "        \"price_unit\": price_unit,\n",
    "        \"irrigation\": irrigation,\n",
    "        \"fertilizer\": fertilizer\n",
    "    })\n",
    "\n",
    "    out[\"revenue_per_ha\"] = out.apply(\n",
    "        lambda r: compute_revenue_per_ha(r[\"pred_yield_hg_ha\"], r[\"price_value\"], r[\"price_unit\"]),\n",
    "        axis=1)\n",
    "\n",
    "    out = out.sort_values(\"revenue_per_ha\", ascending=False)\n",
    "    return out.head(top_k).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43bf622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendement prévu (hg/ha) pour potatoes: 275495.24\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Exemple d'entrée pour prédiction simple\n",
    "area = \"belgium\"\n",
    "item = \"potatoes\"\n",
    "year = 2020\n",
    "avg_rain_mm = 1200.0\n",
    "pesticides_tonnes = 100.0\n",
    "avg_temp = 16.0\n",
    "\n",
    "\n",
    "pred_yield = predict_yield_hg_ha(\n",
    "    model=best_hgb,\n",
    "    area=area,\n",
    "    item=item,\n",
    "    year=year,\n",
    "    avg_rain_mm=avg_rain_mm,\n",
    "    pesticides_tonnes=pesticides_tonnes,\n",
    "    avg_temp=avg_temp,\n",
    "    irrigation=True,       # teste l’effet irrigation\n",
    "    fertilizer=True        # teste l’effet fertilisation\n",
    ")\n",
    "\n",
    "print(f\"Rendement prévu (hg/ha) pour {item}: {pred_yield:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3671f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>pred_yield_hg_ha</th>\n",
       "      <th>pred_yield_t_ha</th>\n",
       "      <th>irrigation</th>\n",
       "      <th>fertilizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>263495.235949</td>\n",
       "      <td>26.349524</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rice, paddy</td>\n",
       "      <td>107571.822978</td>\n",
       "      <td>10.757182</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maize</td>\n",
       "      <td>98545.575830</td>\n",
       "      <td>9.854558</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorghum</td>\n",
       "      <td>87343.681251</td>\n",
       "      <td>8.734368</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soybeans</td>\n",
       "      <td>78064.689589</td>\n",
       "      <td>7.806469</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item  pred_yield_hg_ha  pred_yield_t_ha  irrigation  fertilizer\n",
       "0     potatoes     263495.235949        26.349524       False        True\n",
       "1  rice, paddy     107571.822978        10.757182       False        True\n",
       "2        maize      98545.575830         9.854558       False        True\n",
       "3      sorghum      87343.681251         8.734368       False        True\n",
       "4     soybeans      78064.689589         7.806469       False        True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidate_items = [\"maize\", \"potatoes\", \"rice, paddy\", \"soybeans\", \"sorghum\"]\n",
    "\n",
    "yield_ranking = recommend_by_yield(\n",
    "    model=best_hgb,\n",
    "    area=area,\n",
    "    year=year,\n",
    "    avg_rain_mm=avg_rain_mm,\n",
    "    pesticides_tonnes=pesticides_tonnes,\n",
    "    avg_temp=avg_temp,\n",
    "    candidate_items=candidate_items,\n",
    "    irrigation=False,\n",
    "    fertilizer=True,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "display(yield_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff14f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>pred_yield_hg_ha</th>\n",
       "      <th>pred_yield_t_ha</th>\n",
       "      <th>price_value</th>\n",
       "      <th>price_unit</th>\n",
       "      <th>irrigation</th>\n",
       "      <th>fertilizer</th>\n",
       "      <th>revenue_per_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soybeans</td>\n",
       "      <td>90064.689589</td>\n",
       "      <td>9.006469</td>\n",
       "      <td>300</td>\n",
       "      <td>eur_per_t</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2701.940688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rice, paddy</td>\n",
       "      <td>119571.822978</td>\n",
       "      <td>11.957182</td>\n",
       "      <td>220</td>\n",
       "      <td>eur_per_t</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2630.580106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maize</td>\n",
       "      <td>110545.575830</td>\n",
       "      <td>11.054558</td>\n",
       "      <td>180</td>\n",
       "      <td>eur_per_t</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1989.820365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorghum</td>\n",
       "      <td>99343.681251</td>\n",
       "      <td>9.934368</td>\n",
       "      <td>200</td>\n",
       "      <td>eur_per_t</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1986.873625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>275495.235949</td>\n",
       "      <td>27.549524</td>\n",
       "      <td>50</td>\n",
       "      <td>eur_per_t</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1377.476180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item  pred_yield_hg_ha  pred_yield_t_ha  price_value price_unit  \\\n",
       "0     soybeans      90064.689589         9.006469          300  eur_per_t   \n",
       "1  rice, paddy     119571.822978        11.957182          220  eur_per_t   \n",
       "2        maize     110545.575830        11.054558          180  eur_per_t   \n",
       "3      sorghum      99343.681251         9.934368          200  eur_per_t   \n",
       "4     potatoes     275495.235949        27.549524           50  eur_per_t   \n",
       "\n",
       "   irrigation  fertilizer  revenue_per_ha  \n",
       "0        True        True     2701.940688  \n",
       "1        True        True     2630.580106  \n",
       "2        True        True     1989.820365  \n",
       "3        True        True     1986.873625  \n",
       "4        True        True     1377.476180  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prix fictifs €/t pour chaque culture\n",
    "prices = {\n",
    "    \"maize\": 180,\n",
    "    \"potatoes\": 50,\n",
    "    \"rice, paddy\": 220,\n",
    "    \"soybeans\": 300,\n",
    "    \"sorghum\": 200\n",
    "}\n",
    "\n",
    "revenue_ranking = recommend_by_revenue(\n",
    "    model=best_hgb,\n",
    "    area=area,\n",
    "    year=year,\n",
    "    avg_rain_mm=avg_rain_mm,\n",
    "    pesticides_tonnes=pesticides_tonnes,\n",
    "    avg_temp=avg_temp,\n",
    "    candidate_items=candidate_items,\n",
    "    prices=prices,\n",
    "    price_unit=\"eur_per_t\",\n",
    "    irrigation=True,\n",
    "    fertilizer=True,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "display(revenue_ranking)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12-96sEI1FY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
